---
title: "Datasets"
description: "Understanding datasets, columns, and data management in Radical Whale"
---

## What are Datasets?

Datasets are structured collections of data organized into rows (records) and columns. They serve as the foundation for all data processing activities in Radical Whale. Think of a dataset as a smart spreadsheet where each column can be processed by AI agents to extract, enrich, or analyze information.

[Screenshot Placeholder: Dataset overview with sample data]

## Key Components

### Datasets

The main container that holds all your structured data. Each dataset has:

- **Name and Description**: For easy identification and organization
- **Metadata**: Creation date, owner, and modification history
- **Column Definitions**: Structured schema defining data types and processing rules
- **Records**: The actual data rows containing your information

### Columns

Define the structure and processing rules for your data:

- **Data Types**: Text, numbers, dates, URLs, and more
- **AI Instructions**: How agents should process this column
- **Agent Assignment**: Which AI agent processes this column
- **Validation Rules**: Constraints and formatting requirements

### Records

Individual rows of data within your dataset:

- **Unique IDs**: Every record has a unique identifier
- **Cell Values**: The actual data for each column
- **Processing Status**: Track which cells have been processed
- **Metadata**: Creation and modification timestamps

### Cells

The intersection of records and columns:

- **Value**: The actual data content
- **Status**: Pending, processing, completed, or error
- **Evidence**: AI reasoning and sources for processed values
- **History**: Track changes and processing iterations

[Screenshot Placeholder: Dataset structure diagram showing relationships]

## Data Types

Radical Whale supports various data types for different use cases:

### Text Types

- **Short Text**: Names, titles, brief descriptions (up to 255 characters)
- **Long Text**: Detailed descriptions, content, documents
- **Rich Text**: Formatted content with styling and structure

### Numeric Types

- **Integer**: Whole numbers for counts, IDs, quantities
- **Decimal**: Precise numbers for financial data, measurements
- **Currency**: Monetary values with proper formatting

### Date & Time

- **Date**: Calendar dates (YYYY-MM-DD)
- **DateTime**: Date and time with timezone support
- **Time**: Time values without date component

### Web & Communication

- **URL**: Web addresses with validation
- **Email**: Email addresses with format validation
- **Phone**: Phone numbers with international format support

### Structured Data

- **JSON**: Complex nested data structures
- **Array**: Lists of values
- **Boolean**: True/false values

[Screenshot Placeholder: Column type selection interface]

## Data Import

### CSV Import

The most common way to import data:

1. **File Upload**: Drag and drop or select CSV files
2. **Column Mapping**: Map CSV headers to dataset columns
3. **Data Validation**: Check for formatting issues and errors
4. **Import Preview**: Review data before final import
5. **Processing**: Automatic import with progress tracking

### Supported Formats

- **CSV**: Comma-separated values (most common)
- **TSV**: Tab-separated values
- **Excel**: .xlsx files (coming soon)
- **JSON**: Structured data import (coming soon)

### Import Options

- **Header Detection**: Automatically detect column headers
- **Data Type Inference**: Smart detection of column types
- **Encoding Support**: UTF-8, ASCII, and other character encodings
- **Large File Support**: Handle files with millions of records

[Screenshot Placeholder: CSV import wizard interface]

## Column Configuration

### Basic Settings

- **Column Name**: Display name for the column
- **Data Type**: Choose from supported types
- **Required**: Whether the column must have values
- **Default Value**: Value to use when cell is empty

### AI Processing

- **Agent Assignment**: Select which agent processes this column
- **Processing Instructions**: Detailed instructions for the AI agent
- **Input Dependencies**: Which other columns the agent should consider
- **Output Format**: How results should be structured

### Validation Rules

- **Format Constraints**: Pattern matching, length limits
- **Value Ranges**: Minimum/maximum values for numbers
- **Allowed Values**: Dropdown lists, predefined options
- **Custom Validation**: Advanced rules using expressions

[Screenshot Placeholder: Column configuration form]

## Processing Workflow

### Manual Processing

- **Select Records**: Choose specific rows to process
- **Column Selection**: Pick which columns to process
- **Batch Processing**: Process multiple records simultaneously
- **Real-time Monitoring**: Watch progress as it happens

### Automated Processing

- **Trigger Rules**: Process new records automatically
- **Scheduled Processing**: Run processing jobs at specific times
- **Conditional Processing**: Process based on data conditions
- **Dependency Management**: Process columns in correct order

### Processing Status

Each cell can be in one of several states:

- **Pending**: Waiting to be processed
- **Processing**: Currently being analyzed by an agent
- **Completed**: Successfully processed with results
- **Error**: Processing failed with error details
- **Skipped**: Intentionally not processed

[Screenshot Placeholder: Processing status dashboard]

## Data Quality & Validation

### Automatic Validation

- **Data Type Checking**: Ensure values match column types
- **Format Validation**: Check URLs, emails, phone numbers
- **Range Validation**: Verify numeric values are within bounds
- **Required Field Checking**: Ensure mandatory fields have values

### Quality Metrics

- **Completeness**: Percentage of non-empty cells
- **Validity**: Percentage passing validation rules
- **Consistency**: Data consistency across related columns
- **Processing Coverage**: Percentage of cells processed by agents

### Error Handling

- **Validation Errors**: Clear messages about data issues
- **Processing Errors**: Detailed agent processing failures
- **Bulk Corrections**: Fix common issues across multiple records
- **Manual Review**: Flag suspicious results for human review

[Screenshot Placeholder: Data quality dashboard]

## Advanced Features

### Column Relationships

- **Dependencies**: Define which columns depend on others
- **Calculated Fields**: Columns computed from other columns
- **Lookups**: Reference data from other datasets
- **Aggregations**: Summary calculations across records

### Data Versioning

- **Change Tracking**: Track all modifications to data
- **Rollback**: Revert to previous versions
- **Audit Trail**: See who changed what and when
- **Backup**: Automatic backups of important datasets

### Export & Sharing

- **CSV Export**: Download processed data
- **API Access**: Programmatic access to dataset data
- **Sharing Links**: Share read-only views with external users
- **Integration**: Connect with external systems and tools

## Best Practices

### Dataset Organization

- **Descriptive Names**: Use clear, descriptive dataset names
- **Consistent Structure**: Maintain consistent column naming
- **Documentation**: Add descriptions to datasets and columns
- **Size Management**: Keep datasets focused and manageable

### Data Quality

- **Validation Rules**: Set up appropriate validation for each column
- **Regular Reviews**: Periodically review data quality metrics
- **Error Monitoring**: Set up alerts for processing errors
- **Test Data**: Use sample data to test processing rules

### Performance Optimization

- **Batch Processing**: Process multiple records together
- **Selective Processing**: Only process necessary columns
- **Index Strategy**: Plan for efficient data access patterns
- **Archive Old Data**: Move historical data to reduce active dataset size

## Common Use Cases

### Document Processing

- **Invoice Data**: Extract structured data from invoices
- **Resume Parsing**: Pull relevant information from resumes
- **Contract Analysis**: Identify key terms and clauses
- **Form Processing**: Convert form data to structured records

### Data Enrichment

- **Company Information**: Enhance company records with additional data
- **Contact Enrichment**: Add missing contact information
- **Product Categorization**: Classify products automatically
- **Sentiment Analysis**: Analyze text for sentiment and tone

### Research & Analysis

- **Survey Data**: Process and analyze survey responses
- **Social Media**: Analyze social media posts and engagement
- **Market Research**: Gather and structure market data
- **Academic Research**: Process research data and citations

[Screenshot Placeholder: Use case examples gallery]

## Troubleshooting

### Common Issues

**Import Failures**

- Check file encoding (use UTF-8)
- Verify CSV format and delimiters
- Ensure file size is within limits
- Check for special characters or formatting issues

**Processing Errors**

- Review agent configuration and prompts
- Check column instructions for clarity
- Verify API keys and tool configurations
- Monitor rate limits and quotas

**Performance Issues**

- Reduce batch sizes for large datasets
- Optimize column dependencies
- Consider archiving old data
- Review processing complexity

### Getting Help

For dataset-related issues:

- Check our [dataset management guides](/guides/datasets/creating-datasets)
- Review [data import documentation](/guides/datasets/importing-data)
- Contact [support](mailto:support@radicalwhale.com) for complex issues

## Next Steps

<CardGroup cols={2}>
  <Card
    title="Create Your First Dataset"
    icon="plus"
    href="/guides/datasets/creating-datasets"
  >
    Step-by-step guide to creating and configuring datasets
  </Card>
  <Card
    title="Import Data"
    icon="upload"
    href="/guides/datasets/importing-data"
  >
    Learn how to import CSV files and other data sources
  </Card>
  <Card
    title="Configure Columns"
    icon="columns"
    href="/guides/datasets/managing-columns"
  >
    Set up column types, validation, and processing rules
  </Card>
  <Card title="Understand Agents" icon="robot" href="/concepts/agents">
    Learn how AI agents process your dataset columns
  </Card>
</CardGroup>
